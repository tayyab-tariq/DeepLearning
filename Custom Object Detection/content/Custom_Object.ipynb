{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcM6LWQbaz4X"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow-gpu\n",
        "!pip install tensorflow-gpu==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYoJubNxcefq",
        "outputId": "50f309a7-b3be-4b6e-a6b9-22d44e8f0270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYHjuk6icsFb"
      },
      "source": [
        "## Cloning TFOD 2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cuKFqfHcoDQ",
        "outputId": "82e3bebc-ff0a-47fe-cc35-d79151cf1278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 77038, done.\u001b[K\n",
            "remote: Counting objects: 100% (332/332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (232/232), done.\u001b[K\n",
            "remote: Total 77038 (delta 138), reused 264 (delta 92), pack-reused 76706\u001b[K\n",
            "Receiving objects: 100% (77038/77038), 593.21 MiB | 16.68 MiB/s, done.\n",
            "Resolving deltas: 100% (54652/54652), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MK9cQHLugiqd",
        "outputId": "ba1b6649-0a48-439f-ba7b-cd894190ddad"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqEXw7oehbhW",
        "outputId": "24690899-cb06-4fb3-cbf5-a647498b8105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "cd /content/models/research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60tsFskzhgbC"
      },
      "outputs": [],
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgYr0YBph3Xq",
        "outputId": "314c7e1a-701f-44fe-83fd-27448625be03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 10.03 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/cocodataset/cocoapi.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIc4mVdwiHo6",
        "outputId": "0c33b321-32cc-4248-8e0c-dbd397a0438c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/models/research/cocoapi/PythonAPI\n"
          ]
        }
      ],
      "source": [
        "cd cocoapi/PythonAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVLBps__iH02"
      },
      "outputs": [],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP9_oIqNiS_G"
      },
      "outputs": [],
      "source": [
        "cp -r pycocotools /content/models/research"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdIy7qwriq49"
      },
      "source": [
        "### Install the Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STBqKh00iMAW",
        "outputId": "27a1a3c6-cd8b-4f7e-f7ff-924c974685d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "cd ..                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Xgu2r7qd48gG",
        "outputId": "ad650f6f-3b2f-41bd-c7a3-c2593ef625f7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNAnSwy4i9SQ"
      },
      "outputs": [],
      "source": [
        "cp object_detection/packages/tf2/setup.py ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwbbJbyujeD4"
      },
      "outputs": [],
      "source": [
        "!python -m pip install --use-feature=2020-resolver ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPcWslYDkkRq"
      },
      "source": [
        "###  Test your Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_WtXnhwkd2e"
      },
      "outputs": [],
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3ffbM1u8ZVv",
        "outputId": "ef433bb4-b591-41f3-a1f9-2a2b5dfa8b3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/training_demo/pre-trained-models\n"
          ]
        }
      ],
      "source": [
        "cd /content/training_demo/pre-trained-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qev5FA5Z_AFV",
        "outputId": "991a8c1e-731c-4ea4-adce-7d764e356840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-09-13 09:17:21--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.194.128, 2404:6800:4003:c04::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.194.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90453990 (86M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v1_fp 100%[===================>]  86.26M  49.6MB/s    in 1.7s    \n",
            "\n",
            "2022-09-13 09:17:24 (49.6 MB/s) - ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [90453990/90453990]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK6OxqUv_QnC",
        "outputId": "15035ff5-c171-48db-ae1f-a7db5691913b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "!tar -xvf ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VDtvTGD_TNU",
        "outputId": "998fcf8d-413a-4138-bccf-446e4f8bc567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/training_demo\n"
          ]
        }
      ],
      "source": [
        "cd /content/training_demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNyBmjdu_WhZ",
        "outputId": "dfa97f1a-fd17-4216-8089-0bfb4e3ab8c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created the TFRecord file: /content/training_demo/annotations/train.record\n",
            "Successfully created the TFRecord file: /content/training_demo/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "# Create train data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/train -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/train.record\n",
        "\n",
        "# Create test data:\n",
        "!python generate_tfrecord.py -x /content/training_demo/images/test -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/test.record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5YYvUJeAtUy",
        "outputId": "3f306490-cddb-45df-d9cc-a67493adb7f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  model_main_tf2.py\n",
            "\u001b[01;34mexported_models\u001b[0m/     generate_tfrecord.py        \u001b[01;34mmodels\u001b[0m/\n",
            "exporter_main_v2.py  \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuGCa1YBAwjF",
        "outputId": "58ed063e-c928-4e78-85a3-3d1b287f4129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 09:21:31.573876: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0913 09:21:31.579876 140679107663744 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0913 09:21:31.583500 140679107663744 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0913 09:21:31.583637 140679107663744 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0913 09:21:31.607292 140679107663744 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "I0913 09:21:31.607732 140679107663744 dataset_builder.py:162] Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "I0913 09:21:31.607901 140679107663744 dataset_builder.py:79] Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0913 09:21:31.607989 140679107663744 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0913 09:21:31.608060 140679107663744 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0913 09:21:31.610361 140679107663744 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0913 09:21:31.630666 140679107663744 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0913 09:21:37.959213 140679107663744 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0913 09:21:40.734280 140679107663744 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0913 09:21:42.266079 140679107663744 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2022-09-13 09:21:49.009958: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 155750400 exceeds 10% of free system memory.\n",
            "2022-09-13 09:21:49.127110: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 155750400 exceeds 10% of free system memory.\n",
            "2022-09-13 09:21:49.257512: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 155750400 exceeds 10% of free system memory.\n",
            "2022-09-13 09:21:51.026331: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 155750400 exceeds 10% of free system memory.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.178998 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.180201 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.182211 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.183074 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.185106 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.185954 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.188019 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.188875 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.190806 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0913 09:22:17.191636 140679107663744 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0913 09:22:17.790892 140674093991680 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "2022-09-13 09:22:52.270619: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 155750400 exceeds 10% of free system memory.\n",
            "INFO:tensorflow:Step 100 per-step time 0.864s\n",
            "I0913 09:23:43.891927 140679107663744 model_lib_v2.py:707] Step 100 per-step time 0.864s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23485455,\n",
            " 'Loss/localization_loss': 0.10235318,\n",
            " 'Loss/regularization_loss': 0.77657044,\n",
            " 'Loss/total_loss': 1.1137781,\n",
            " 'learning_rate': 0.014666351}\n",
            "I0913 09:23:43.892335 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.23485455,\n",
            " 'Loss/localization_loss': 0.10235318,\n",
            " 'Loss/regularization_loss': 0.77657044,\n",
            " 'Loss/total_loss': 1.1137781,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 0.547s\n",
            "I0913 09:24:38.642203 140679107663744 model_lib_v2.py:707] Step 200 per-step time 0.547s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.107914366,\n",
            " 'Loss/localization_loss': 0.026542757,\n",
            " 'Loss/regularization_loss': 0.775797,\n",
            " 'Loss/total_loss': 0.9102541,\n",
            " 'learning_rate': 0.0159997}\n",
            "I0913 09:24:38.642711 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.107914366,\n",
            " 'Loss/localization_loss': 0.026542757,\n",
            " 'Loss/regularization_loss': 0.775797,\n",
            " 'Loss/total_loss': 0.9102541,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 0.576s\n",
            "I0913 09:25:36.254381 140679107663744 model_lib_v2.py:707] Step 300 per-step time 0.576s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.107218035,\n",
            " 'Loss/localization_loss': 0.032400247,\n",
            " 'Loss/regularization_loss': 0.77492386,\n",
            " 'Loss/total_loss': 0.91454214,\n",
            " 'learning_rate': 0.01733305}\n",
            "I0913 09:25:36.254744 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.107218035,\n",
            " 'Loss/localization_loss': 0.032400247,\n",
            " 'Loss/regularization_loss': 0.77492386,\n",
            " 'Loss/total_loss': 0.91454214,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 0.528s\n",
            "I0913 09:26:29.060678 140679107663744 model_lib_v2.py:707] Step 400 per-step time 0.528s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.57408684,\n",
            " 'Loss/localization_loss': 0.10671773,\n",
            " 'Loss/regularization_loss': 0.7833037,\n",
            " 'Loss/total_loss': 1.4641082,\n",
            " 'learning_rate': 0.0186664}\n",
            "I0913 09:26:29.061029 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.57408684,\n",
            " 'Loss/localization_loss': 0.10671773,\n",
            " 'Loss/regularization_loss': 0.7833037,\n",
            " 'Loss/total_loss': 1.4641082,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 0.543s\n",
            "I0913 09:27:23.366877 140679107663744 model_lib_v2.py:707] Step 500 per-step time 0.543s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20250905,\n",
            " 'Loss/localization_loss': 0.053103577,\n",
            " 'Loss/regularization_loss': 0.78241587,\n",
            " 'Loss/total_loss': 1.0380285,\n",
            " 'learning_rate': 0.01999975}\n",
            "I0913 09:27:23.367264 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.20250905,\n",
            " 'Loss/localization_loss': 0.053103577,\n",
            " 'Loss/regularization_loss': 0.78241587,\n",
            " 'Loss/total_loss': 1.0380285,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 0.540s\n",
            "I0913 09:28:17.330195 140679107663744 model_lib_v2.py:707] Step 600 per-step time 0.540s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15873076,\n",
            " 'Loss/localization_loss': 0.026497377,\n",
            " 'Loss/regularization_loss': 0.7812627,\n",
            " 'Loss/total_loss': 0.96649086,\n",
            " 'learning_rate': 0.0213331}\n",
            "I0913 09:28:17.330652 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.15873076,\n",
            " 'Loss/localization_loss': 0.026497377,\n",
            " 'Loss/regularization_loss': 0.7812627,\n",
            " 'Loss/total_loss': 0.96649086,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 0.576s\n",
            "I0913 09:29:14.924657 140679107663744 model_lib_v2.py:707] Step 700 per-step time 0.576s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25655696,\n",
            " 'Loss/localization_loss': 0.15712596,\n",
            " 'Loss/regularization_loss': 0.78001624,\n",
            " 'Loss/total_loss': 1.1936991,\n",
            " 'learning_rate': 0.02266645}\n",
            "I0913 09:29:14.926388 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.25655696,\n",
            " 'Loss/localization_loss': 0.15712596,\n",
            " 'Loss/regularization_loss': 0.78001624,\n",
            " 'Loss/total_loss': 1.1936991,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 0.538s\n",
            "I0913 09:30:08.779304 140679107663744 model_lib_v2.py:707] Step 800 per-step time 0.538s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10502543,\n",
            " 'Loss/localization_loss': 0.047909275,\n",
            " 'Loss/regularization_loss': 0.77868414,\n",
            " 'Loss/total_loss': 0.9316188,\n",
            " 'learning_rate': 0.023999799}\n",
            "I0913 09:30:08.779736 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.10502543,\n",
            " 'Loss/localization_loss': 0.047909275,\n",
            " 'Loss/regularization_loss': 0.77868414,\n",
            " 'Loss/total_loss': 0.9316188,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 0.547s\n",
            "I0913 09:31:03.507276 140679107663744 model_lib_v2.py:707] Step 900 per-step time 0.547s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09477193,\n",
            " 'Loss/localization_loss': 0.03350048,\n",
            " 'Loss/regularization_loss': 0.7772452,\n",
            " 'Loss/total_loss': 0.90551764,\n",
            " 'learning_rate': 0.025333151}\n",
            "I0913 09:31:03.507679 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.09477193,\n",
            " 'Loss/localization_loss': 0.03350048,\n",
            " 'Loss/regularization_loss': 0.7772452,\n",
            " 'Loss/total_loss': 0.90551764,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.556s\n",
            "I0913 09:31:59.112226 140679107663744 model_lib_v2.py:707] Step 1000 per-step time 0.556s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12364156,\n",
            " 'Loss/localization_loss': 0.040908925,\n",
            " 'Loss/regularization_loss': 0.7758482,\n",
            " 'Loss/total_loss': 0.9403987,\n",
            " 'learning_rate': 0.0266665}\n",
            "I0913 09:31:59.112632 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.12364156,\n",
            " 'Loss/localization_loss': 0.040908925,\n",
            " 'Loss/regularization_loss': 0.7758482,\n",
            " 'Loss/total_loss': 0.9403987,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.586s\n",
            "I0913 09:32:57.693414 140679107663744 model_lib_v2.py:707] Step 1100 per-step time 0.586s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08367787,\n",
            " 'Loss/localization_loss': 0.03837213,\n",
            " 'Loss/regularization_loss': 0.77426165,\n",
            " 'Loss/total_loss': 0.89631164,\n",
            " 'learning_rate': 0.02799985}\n",
            "I0913 09:32:57.693835 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.08367787,\n",
            " 'Loss/localization_loss': 0.03837213,\n",
            " 'Loss/regularization_loss': 0.77426165,\n",
            " 'Loss/total_loss': 0.89631164,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.544s\n",
            "I0913 09:33:52.046166 140679107663744 model_lib_v2.py:707] Step 1200 per-step time 0.544s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08272247,\n",
            " 'Loss/localization_loss': 0.024073424,\n",
            " 'Loss/regularization_loss': 0.77258694,\n",
            " 'Loss/total_loss': 0.87938285,\n",
            " 'learning_rate': 0.0293332}\n",
            "I0913 09:33:52.046515 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.08272247,\n",
            " 'Loss/localization_loss': 0.024073424,\n",
            " 'Loss/regularization_loss': 0.77258694,\n",
            " 'Loss/total_loss': 0.87938285,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.556s\n",
            "I0913 09:34:47.654809 140679107663744 model_lib_v2.py:707] Step 1300 per-step time 0.556s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09483868,\n",
            " 'Loss/localization_loss': 0.043644514,\n",
            " 'Loss/regularization_loss': 0.77083296,\n",
            " 'Loss/total_loss': 0.9093162,\n",
            " 'learning_rate': 0.03066655}\n",
            "I0913 09:34:47.655293 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.09483868,\n",
            " 'Loss/localization_loss': 0.043644514,\n",
            " 'Loss/regularization_loss': 0.77083296,\n",
            " 'Loss/total_loss': 0.9093162,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.576s\n",
            "I0913 09:35:45.254305 140679107663744 model_lib_v2.py:707] Step 1400 per-step time 0.576s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07050294,\n",
            " 'Loss/localization_loss': 0.017335434,\n",
            " 'Loss/regularization_loss': 0.76904076,\n",
            " 'Loss/total_loss': 0.8568791,\n",
            " 'learning_rate': 0.0319999}\n",
            "I0913 09:35:45.254745 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.07050294,\n",
            " 'Loss/localization_loss': 0.017335434,\n",
            " 'Loss/regularization_loss': 0.76904076,\n",
            " 'Loss/total_loss': 0.8568791,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.562s\n",
            "I0913 09:36:41.479248 140679107663744 model_lib_v2.py:707] Step 1500 per-step time 0.562s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.079139866,\n",
            " 'Loss/localization_loss': 0.022903254,\n",
            " 'Loss/regularization_loss': 0.7671672,\n",
            " 'Loss/total_loss': 0.86921036,\n",
            " 'learning_rate': 0.03333325}\n",
            "I0913 09:36:41.479654 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.079139866,\n",
            " 'Loss/localization_loss': 0.022903254,\n",
            " 'Loss/regularization_loss': 0.7671672,\n",
            " 'Loss/total_loss': 0.86921036,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.544s\n",
            "I0913 09:37:35.837621 140679107663744 model_lib_v2.py:707] Step 1600 per-step time 0.544s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.095183924,\n",
            " 'Loss/localization_loss': 0.049651593,\n",
            " 'Loss/regularization_loss': 0.76519686,\n",
            " 'Loss/total_loss': 0.9100324,\n",
            " 'learning_rate': 0.034666598}\n",
            "I0913 09:37:35.837970 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.095183924,\n",
            " 'Loss/localization_loss': 0.049651593,\n",
            " 'Loss/regularization_loss': 0.76519686,\n",
            " 'Loss/total_loss': 0.9100324,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.530s\n",
            "I0913 09:38:28.791891 140679107663744 model_lib_v2.py:707] Step 1700 per-step time 0.530s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07400672,\n",
            " 'Loss/localization_loss': 0.017583981,\n",
            " 'Loss/regularization_loss': 0.7631592,\n",
            " 'Loss/total_loss': 0.8547499,\n",
            " 'learning_rate': 0.03599995}\n",
            "I0913 09:38:28.792299 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.07400672,\n",
            " 'Loss/localization_loss': 0.017583981,\n",
            " 'Loss/regularization_loss': 0.7631592,\n",
            " 'Loss/total_loss': 0.8547499,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.590s\n",
            "I0913 09:39:27.750871 140679107663744 model_lib_v2.py:707] Step 1800 per-step time 0.590s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08438534,\n",
            " 'Loss/localization_loss': 0.01348442,\n",
            " 'Loss/regularization_loss': 0.7610455,\n",
            " 'Loss/total_loss': 0.85891527,\n",
            " 'learning_rate': 0.037333302}\n",
            "I0913 09:39:27.751260 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.08438534,\n",
            " 'Loss/localization_loss': 0.01348442,\n",
            " 'Loss/regularization_loss': 0.7610455,\n",
            " 'Loss/total_loss': 0.85891527,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.557s\n",
            "I0913 09:40:23.423295 140679107663744 model_lib_v2.py:707] Step 1900 per-step time 0.557s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07342876,\n",
            " 'Loss/localization_loss': 0.01795545,\n",
            " 'Loss/regularization_loss': 0.75886744,\n",
            " 'Loss/total_loss': 0.8502517,\n",
            " 'learning_rate': 0.03866665}\n",
            "I0913 09:40:23.423745 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.07342876,\n",
            " 'Loss/localization_loss': 0.01795545,\n",
            " 'Loss/regularization_loss': 0.75886744,\n",
            " 'Loss/total_loss': 0.8502517,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.534s\n",
            "I0913 09:41:16.848844 140679107663744 model_lib_v2.py:707] Step 2000 per-step time 0.534s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05937951,\n",
            " 'Loss/localization_loss': 0.021447442,\n",
            " 'Loss/regularization_loss': 0.75659114,\n",
            " 'Loss/total_loss': 0.8374181,\n",
            " 'learning_rate': nan}\n",
            "I0913 09:41:16.849339 140679107663744 model_lib_v2.py:708] {'Loss/classification_loss': 0.05937951,\n",
            " 'Loss/localization_loss': 0.021447442,\n",
            " 'Loss/regularization_loss': 0.75659114,\n",
            " 'Loss/total_loss': 0.8374181,\n",
            " 'learning_rate': nan}\n"
          ]
        }
      ],
      "source": [
        "!python model_main_tf2.py --model_dir=/content/training_demo/models/ssd_mobilenet_v1_fpn --pipeline_config_path=/content/training_demo/models/ssd_mobilenet_v1_fpn/pipeline.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRdUAJj7E5oP",
        "outputId": "7eb2e36a-eee8-4e08-cd3e-18c6a80c8ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-09-13 09:41:54.386630: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "W0913 09:41:54.519136 140566357206912 deprecation.py:628] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.map_fn(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fd72e3bd550>, because it is not built.\n",
            "W0913 09:42:11.072570 140566357206912 save_impl.py:72] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fd72e3bd550>, because it is not built.\n",
            "W0913 09:42:24.256121 140566357206912 save.py:238] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 252). These functions will not be directly callable after loading.\n",
            "INFO:tensorflow:Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n",
            "I0913 09:42:27.998782 140566357206912 builder_impl.py:780] Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n",
            "INFO:tensorflow:Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n",
            "I0913 09:42:28.355270 140566357206912 config_util.py:254] Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n"
          ]
        }
      ],
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training_demo/models/ssd_mobilenet_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training_demo/models/ssd_mobilenet_v1_fpn --output_directory /content/training_demo/exported_models/my_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNPidfTfgPH4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Object Detection (On Image) From TF2 Saved Model\n",
        "=====================================\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import argparse\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Enable GPU dynamic memory allocation\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# PROVIDE PATH TO IMAGE DIRECTORY\n",
        "\n",
        "# PROVIDE PATH TO MODEL DIRECTORY\n",
        "PATH_TO_MODEL_DIR = '/content/training_demo/exported_models/my_model'\n",
        "\n",
        "# PROVIDE PATH TO LABEL MAP\n",
        "PATH_TO_LABELS = '/content/training_demo/annotations/label_map.pbtxt'\n",
        "\n",
        "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
        "MIN_CONF_THRESH = float(0.60)\n",
        "\n",
        "# LOAD THE MODEL\n",
        "\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# LOAD LABEL MAP DATA FOR PLOTTING\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)\n",
        "\n",
        "\n",
        "# CLOSES WINDOW ONCE KEY IS PRESSED\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e8QsUmY2PvuN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  IMAGE_PATHS = f'Path To Image'\n",
        "\n",
        "  print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
        "\n",
        "  image = cv2.imread(IMAGE_PATHS)\n",
        "  image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  image_expanded = np.expand_dims(image_rgb, axis=0)\n",
        "\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "  # input_tensor = np.expand_dims(image_np, 0)\n",
        "  detections = detect_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "  image_with_detections = image.copy()\n",
        "\n",
        "  # SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=0.2,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "  print('Done')\n",
        "  # DISPLAYS OUTPUT IMAGE\n",
        "  cv2_imshow(image_with_detections)             # For Google Colab "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "iTV0rp0TFTFX",
        "outputId": "e3c4d1d4-ad76-4b90-c74b-92895b017990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/training_demo/exported_models/ (stored 0%)\n",
            "  adding: content/training_demo/exported_models/my_model/ (stored 0%)\n",
            "  adding: content/training_demo/exported_models/my_model/pipeline.config (deflated 68%)\n",
            "  adding: content/training_demo/exported_models/my_model/saved_model/ (stored 0%)\n",
            "  adding: content/training_demo/exported_models/my_model/saved_model/variables/ (stored 0%)\n",
            "  adding: content/training_demo/exported_models/my_model/saved_model/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/training_demo/exported_models/my_model/saved_model/variables/variables.index (deflated 79%)\n",
            "  adding: content/training_demo/exported_models/my_model/saved_model/assets/ (stored 0%)\n",
            "  adding: content/training_demo/exported_models/my_model/saved_model/saved_model.pb (deflated 92%)\n",
            "  adding: content/training_demo/exported_models/my_model/checkpoint/ (stored 0%)\n",
            "  adding: content/training_demo/exported_models/my_model/checkpoint/ckpt-0.data-00000-of-00001 (deflated 7%)\n",
            "  adding: content/training_demo/exported_models/my_model/checkpoint/checkpoint (deflated 42%)\n",
            "  adding: content/training_demo/exported_models/my_model/checkpoint/ckpt-0.index (deflated 81%)\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7137ee48-b72e-4155-898a-a36ce19da1c2\", \"file.zip\", 81267661)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!zip -r /content/file.zip /content/training_demo/exported_models\n",
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
